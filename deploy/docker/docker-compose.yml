version: '3'

services:
  ollama-agent:
    build:
      context: ../../
      dockerfile: Dockerfile
    image: ollama-agent:latest
    container_name: ollama-agent
    ports:
      - "11434:11434"
    environment:
      - RUST_LOG=info
      - OLLAMA_PROXY_PORT=11434
      - OLLAMA_REMOTE_URL=https://api.ollama.ai
      # Uncomment and fill if you need API key authentication
      # - OLLAMA_API_KEY=your_api_key_here
    restart: unless-stopped
    # For production deployment, consider adding health checks
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    volumes:
      # Optional volume for persistent configuration
      - ollama_agent_data:/home/ollama/.ollama

volumes:
  ollama_agent_data: